# HW06 – Report


## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (12000 строк, 30 столбцов)
- Целевая переменная: `target` (класс 0: 67,66%; класс 1: 32,34%)
- Признаки: 1) Числовые признаки: 24 столбца (num01, num02 ...); 2) Категориальные признаки: 6 столбцов (cat_contract, cat_region, cat_payment ...)

## 2. Protocol

- Разбиение: train/test (доли: 75% обучающие данные и 25% тестовые данные, `random_state` = 42)
- Подбор: CV на train (имеется 5 фолдов, что оптимизировали)
- Метрики: accuracy (общая точность классификации, отражающая долю правильных предсказаний), F1 (более информативная метрика для дисбалансированных классов (нужна для бинарных классификаторов для показа качества модели к различным порогам)), ROC-AUC (для оценки качества моделей в задаче классификации (показ качества модели по отношению к различным порогам))

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.
1) DummyClassifier: базовая модель, предсказывающая наиболее частый класс, использовалась для оценки базовой производительности.
2) LogisticRegression: модель из S05, использована как более сложная baseline модель.
3) DecisionTreeClassifier: модель с контролем сложности через параметры max_depth и min_samples_leaf.
4) RandomForestClassifier: ансамбль решающих деревьев. Подбирались параметры max_depth, min_samples_leaf, max_features.
5) AdaBoostClassifier: метод бустинга для улучшения производительности на слабых классификаторах.

## 4. Results

- Таблица/список финальных метрик на test по всем моделям
| Модель                 | Accuracy | F1-метрика | ROC-AUC |
| ---------------------- | -------- | ---------- | ------- |
| DummyClassifier        | 0.677    | 0.0        | 0.5     |
| LogisticRegression     | 0.828    | 0.708      | 0.875   |
| DecisionTreeClassifier | 0.868    | 0.784      | 0.879   |
| RandomForestClassifier | 0.926    | 0.879      | 0.967   |
| AdaBoostClassifier     | 0.841    | 0.734      | 0.902   |


- Победитель: RandomForestClassifier (выше всего показатели)

## 5. Analysis

- Устойчивость: при изменении 'random_state' результаты моделей также будут меняться (минимальные изменения в StackingClassifier).
- Ошибки: RandomForestClassifier confusion matrix показала, что модель хорошо различает как класс 0, так и класс 1.
Коментарий: модель хорошо справилась с задачей.
- Интерпретация: permutation importance (наиболее важными признаками оказались num01, num12, cat_contract, num18, которые сильно влияют на предсказания модели.); Выводы: важность этих признаков подтверждает, что как числовые, так и категориальные признаки могут быть полезными для классификации.

## 6. Conclusion

1) Деревья решений и ансамбли хорошо справляются с классификацией.
2) Ансамбли моделей дают лучшие результаты, чем одиночные модели.
3) Метрики, такие как ROC-AUC, особенно полезны в задачах классификации, где важно оценить модель по различным порогам.