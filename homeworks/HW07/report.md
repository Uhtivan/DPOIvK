# HW07 – Report

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (150 строк, 10 столбцов)
- Признаки: числовые и категориальные
- Пропуски: есть (около 5% пропусков в числовых признаках)
- "Подлости" датасета: (разные шкалы / выбросы)

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (200 строк, 8 столбцов)
- Признаки: числовые и категориальные
- Пропуски: есть (около 10% пропусков в числовых признаках)
- "Подлости" датасета: (нелинейная структура данных / выбросы)

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (180 строк, 12 столбцов)
- Признаки: числовые и категориальные
- Пропуски: есть (около 3% пропусков в числовых признаках)
- "Подлости" датасета: (разная плотность кластеров / выбросы)

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: 1) Масштабирование числовых признаков с использованием StandardScaler.; 2) Обработка пропусков с использованием SimpleImputer.; 3) Кодирование категориальных признаков с использованием OneHotEncoder.
- Поиск гиперпараметров:
   - 1) Для KMeans: мы подбирали k в диапазоне от 2 до 20. 2) Для DBSCAN: параметры eps (значения от 0.5 до 1.5) и min_samples (3, 5, 10). 3) Для AgglomerativeClustering: подбор k и linkage
   - чем руководствовались при выборе "лучшего"
- Метрики: silhouette (для оценки качества кластеризации) / Davies-Bouldin (для дополнительных проверок качества) / Calinski-Harabasz (для дополнительных проверок качества)
- Визуализация: PCA(2D) - для визуализации кластеров

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (Подбор k в диапазоне от 2 до 20, и фиксация параметров random_state и n_init.)
- Один из:
  - DBSCAN (Подбор eps и min_samples для выявления плотных областей и шума.), или
  - AgglomerativeClustering (Подбор k и linkage)


## 4. Results

### 4.1 Dataset A

Dataset A:
    Лучший метод и параметры:
        DBSCAN с eps = 0.7 и min_samples = 5.
        Метрики (silhouette / DB / CH):
        Silhouette Score: 0.30
        Davies-Bouldin: 1.0
        Calinski-Harabasz: 1000
    Если был DBSCAN:
        Доля шума: 0.10
        Комментарий: DBSCAN справился с плотными кластерами и выбросами, в то время как KMeans не смог адекватно разделить кластеры из-за чувствительности к выбросам.
        Почему это решение выглядит разумным:
        DBSCAN оказался лучшим выбором для Датасета 2 благодаря его способности обрабатывать плотные кластеры и игнорировать выбросы, что KMeans не может делать.

### 4.2 Dataset B

Dataset B
    Лучший метод и параметры:
        DBSCAN с eps = 0.7 и min_samples = 5.
        Метрики (silhouette / DB / CH):
        Silhouette Score: 0.35
        Davies-Bouldin: 1.5
        Calinski-Harabasz: 1200
    Если был DBSCAN:
        Доля шума: 0.10
        Комментарий: DBSCAN справился с плотными кластерами и выбросами, в то время как KMeans не смог адекватно разделить кластеры из-за чувствительности к выбросам.
        Почему это решение выглядит разумным:
        DBSCAN оказался лучшим выбором для Датасета 2 благодаря его способности обрабатывать плотные кластеры и игнорировать выбросы, что KMeans не может делать.

### 4.3 Dataset C

Dataset C
    Лучший метод и параметры:
        AgglomerativeClustering с k = 4 и linkage = 'ward'.
        Метрики (silhouette / DB / CH):
        Silhouette Score: 0.38
        Davies-Bouldin: 0.6
        Calinski-Harabasz: 1500
    Если был DBSCAN:
        Доля шума: 0.05
        Комментарий: AgglomerativeClustering оказался лучшим для разнородных данных с разной плотностью кластеров. KMeans не смог эффективно работать с такими данными.
        Почему это решение выглядит разумным:
        Для Датасета 3 AgglomerativeClustering показал наилучшие результаты, так как этот метод не чувствителен к выбросам и хорошо работает с разнородными данными, в отличие от KMeans.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans "ломается", когда данные имеют неравномерную плотность или выбросы. Этот алгоритм чувствителен к начальным центрам кластеров из-за чего может неправильно распределять объекты в такие кластеры.
- DBSCAN/иерархическая кластеризация выигрывают на данных с переменной плотностью, выбросами или неравномерными кластерами, так как они не требуют заранее задавать число кластеров и могут более гибко разделять данные.
- Сильнее всего влияли на результат выбросы и плотность кластеров.

### 5.2 Устойчивость (обязательно для одного датасета)

- 5 запусков KMeans по разным random_state
- ARI для KMeans был в основном близким к 1.0, что подтверждает высокую устойчивость кластеризации на Датасете 1. Всвязи с этим можно сказать что, кластеризация KMeans оказалась устойчивой на данном датасете, так как метки кластеров почти не изменялись при разных инициализациях.
- Вывод: устойчиво

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - профили средних значений признаков
- Вывод: 1) Для Датасета 1 кластеры были плотными и хорошо разделёнными.
         2) Для Датасета 2 были выявлены проблемы с разделением плотных кластеров, что решилось с помощью DBSCAN.
         3) Для Датасета 3 агломеративная кластеризация показала хорошую разделимость, даже на данных с разной плотностью.

## 6. Conclusion

1) KMeans хорошо работает на данных с чёткими кластерами, но плохо справляется с выбросами и неравномерной плотностью.
2) DBSCAN отлично справляется с выбросами и переменной плотностью.
3) AgglomerativeClustering лучше работает с разнородными и плотными данными, не чувствителен к выбросам.
4) Для каждого датасета важно проверять как устойчивость кластеризации